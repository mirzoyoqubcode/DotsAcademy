courses = [
    {
        "name": "Generative AI for Beginners",
        "description": "Generative AI for Beginners is a 12 lesson course teaching you everything you need to know about building Generative AI applications. Each lesson covers an important aspect of working with LLMs including an Introduction to Generative AI, comparing different LLMs and types of applications you can build. This is a hands on course and all the code is available in the Github Repo above.",
        "instructor": "Samuel Lynn-Evans",
        "content": """
VIDEO 1: hi everyone and welcome to the first lesson of the generative AI for beginners course this course is based on an open source curriculum with the same name available on gab I'm Carlota cucho AI Cloud Advocate at Microsoft and in this video I'm going to introduce you to generative Ai and large language models large language models represent the Pinnacle of AI technology pushing the boundaries of what was once thought impossible they've concered numerous challenges that older language models struggled with achieving human level performance in various task they have several capabilities and applications but for this course we'll explore how large language models are revolutionizing education through a fictional startup that we'll be referring to as our startup our startup works in the education domain with the ambitious mission of improving accessibility in learning on a global scale ensuring Equitable access to education and providing personalized learning experiences to every learner according to their needs in this course we'll dive into how our startup harnesses the power of generative AI to unlock new possibilities in education we'll also examine how to address the inevitable challenges tied to the social impact of these technology and its technology limitations but let's start by defining some basic concept with will be using throughout the course despite the recent hype surrounding gen AI this technology has been decades in the making with its Origins tressing back to the 1950s 1960s the earliest AI prototypes consisted of typewritten chatbots relying on knowledge bases maintained by experts these chatbots generated responses based on keywords found in user input but it soon became clear that this approach had scalability Li itations a significant Turning Point arrived in the 1990s when a statistical approach was applied to text analysis this gave birth to Mach learning algorithms which could learn pattern from data without explicit programming these algorithms allowed machines to simulate human language understanding Paving the way for the AI we know today in more recent times advancements in Hardware technology allowed for the development of advanced masch learning algorith particularly neural networks these Innovation significantly improved natural language processing enabling machines to understand the context of words in sentences this breakthrough technology powered the birth of viritual assistance in the early 21st century and this virtual assistance excelled at interpreting human language identifying needs and taking actions to fulfill them such as answering queries with predefined scripts or connecting to third part services and so we arrived at generative AI a subset of deep learning after Decades of AI research a new model architecture known as the Transformer emerged Transformers could handle longer tax sequences as input and were based on the attention mechanism enabling them to focus on the most relevant information regardless of its order in the text today most generative AI models often referred to as large language models are built upon the Transformer AR Ure these models train on vast amounts of data from sources like books articles and websites possess a unique adaptability they can tackle a wide range of task and generate grammatical correct text with a hint of creativity but let's dive deeper into the mechanism of large language models and shed light on the inner workings of models like open GPT one of the key Concepts to grasp is tokenization large language models receive text as input and produce text as output however these models work much more efficiently with numbers than withdraw text sequences that's where the tokenizer comes into play a token is essentially a chunk of text which can vary in length and typically consist of a sequence of characters the tokenizer primary job is to break down the input tax into an array of these tokens once we have these tokens they are further ma to token indices and these token indices are essentially integer and codings of the original text Chance making it easier for the model to process and understand now let's move to predicting output tokens given an input sequence of n tokens with n baring from one model to another the model is designed to predict a single tokens as output but here here's where it gets interesting the predicted token is then incorporated into the input of the next iteration creating an expanding window pattern and this pattern allows the model to provide more coherent and contextually relevant responses often extending to one or multiple sentences finally let's dive into the selection process the model chooses the output token based on its probability of occurring after the current text sequence this probability distribution is calculating using the model's training data however here's the twist the model does always choose the token with the highest probability from the distribution to simulate the process of creative thinking a degree of Randomness is introduced into the selection process and this means that the model doesn't produce the exact same output for the same input every time and that's the element that allows gener TBI to generate text that feels creative and engaging we say that the main capability of a large language model is generating a text from scratch starting from a textual input written in natural language but but what kind of textual input and output first of all let me say that the input of a large language model is known as prompt while the output is known as completion term that refers to the model mechanism of generating the next token to complete the current input let's do some examples of prompts and completions by using the openai CH gbt playground a prompt may include an instruction specifying the type of output we expect from the model such as a request to write an assignment for high school students including four open-ended questions about Louis 14th and this court a prompt might also include a question asked in the form of a conversation with an agent like who is Louis 14th and why he is an important historical character another example of prompt is a chunk of text to complete which implicitly is an ask for writing assistance the examples I justed are quite simple and won't be an exhaustive demonstration of large language models capabilities they just want to show the potential of using generative AI in particular but not limited to the educational context that's all for this lesson in the following lesson we are going to explore different types of generative AI models and we're going to cover how to test iterate to improve performance and compare different models to find the most suitable for a specific use case
VIDEO 2: hey welcome back to the generative AI series by Microsoft and gical systems I'm paabo Lopez Global Cloud advocate in application development and artificial intelligence teams it is a pleasure to teach you about this amazing new platform and to deliver impact to everyone remember this series is just the beginning you can learn more on the website or search through your a practice with imagin cup or grow it into your setup with father if you had an idea Microsoft can help you make it to fruition all the links are in the description below but if that delay any longer let's start using some generative AI today now the first chapter we introduce you some basics of generative AI but remember we're doing a startup an education startup at that with J of AI and using this to implement new technology T in your company how to explore this landscape is really difficult you have bunch of news firms like llms uh tokens Etc don't worry we are here to make it easy to everyone but let's start to see how can we use llms and how can we make them suitable to our use cases for this we need to understand the different types of LMS based on their architecture train data and use case first let's understand exactly how Foundation models versus llms differ and how can we use them for our Advan what is a foundation model Foundation model was a term coined by sord professors and researchers defining AI models with the same criteria first they need to be trained using unsupervised data or self-supervised data it means that they do not require any classification or labeling of our data second they need to beat very large models they can need to base on very deep neuron Networks and they had to have billions of parameters three they need to be intended as Foundation which means that they need can be used as space fors of new models so it can train and make better and more specialist models but what about llms well llms are type of foundation model because they can be used in a lot of small tests like text summarization translations um for instance we can find Mini S Etc this means that yes llms are can be Foundation models but this does not mean that our foundation models are llms Imagine jet GPT J GPT uses GPT 3.5 this is a foundation model and is a llf but me that our foundation models are language models now let's think about open Source modules and proprietary modules open source modules are usually open to the public it means that you can analyze they have more pros of Licensing which means that you can analyze take a look you can customize a mod you can do a bunch of things with those new amazing models however usually they the most they are the most funded models and can have older architectures one of the examples would be llama but what about proprietary models usually they're maintained by companies so that means that they are made available by some form however it does not mean usually that you can analyze it deeply when sometimes you need some kind of subscription or payment to continue using and usually you should interest the company doing the model to maintain your data safely one of the big examples of this this private kind of models are oi especially DBT oh great you know all of this but you may imagine that you want to generate a lot of things right so first let's start with a more basic let's think about embeddings usually when they have an LM you have to pass the context to another LM do you don't need know about anything about contest at this point but it is important to understand that sometimes you want to have some data to pass another model and then you can process from that these are embeddings so sometimes I have models that just do that make BRS and create this number representation this embedding so this can pass to another llm so some examples we can use this is for surate models imagine that you want a model that want to do another thing we can process it should be a very specific model then you can use this is a surrogate model then they plug the edings plug to that and boom you have some examples of how to use in settings but sometimes you want more than this imagine that you want to generate images but you may think that the only that's their only use that you can use images but not only that you can use for instance to in translate in that image you can edit this image you can do in painting in a lot more you are normally TR a big they add a set of images you can think about lion 5B you can as well generate new images as well edit and do more FS these are amazing for some instance you can use DOL free which is available on bang shot or a stable diffusion now we have the text ones they are the text the text and code generation so these are usually used for guess it to generate text compliment getting context or maybe some typ of way writing more on the context that you already have these are usually trained at as you guessed it on for a big data set of taex book Corpus and you can use it like word code for instance you can get par so you often trade these large data sets of images with code or text and there is a very big data sets a code ver a GitHub Cod pilot and you can generate new code Which F fixes of the old one great Le a lot but how this exactly work so imagine that you have a manager right and it gives you a task to write quest for students you have two colleagues one oversees creating content and other reviewing content the content creator would be like a decoder so he can look at the topic see what you already wrot it and then you can create basically the quest around that right so we can create okay what do I need to create with this it can be very good and write and very engaging content he can be amazing at it however we have a n sh here sometimes he's not the best at understanding what he is doing so sometimes of they call their only models you can imagine like TBT free but sometimes they have they en colder only model he can review the course greatly but has no creativity in how to write anything that he is doing the reviewers like the in caller only model you can you can see the course and see if it's correct or he do the best creative in writing it so sometimes we have models like that to just verify and see okay this looks good these can be models like ber Alberta herberta Etc that can analyze and see if makes sense but it's not the best at creating those so then I have both that can create and can review we can have Bart or T5 for example now we we are having great progress but how you make those available okay so now you know everything about this how can we use those very simple you can use those on our available model and Hardware you can just use it deploying directly on the cloud or Hardware these are directly run by your company to they run locally or not rep on cloud VMS and you can scale dependently if you are on cloud or not if you're on har which means that you have a lot of expenses so this say imagine like Falcon you want to use Falcon you need to probably deploy it somewhere services are normally very optimized for use because the model has already trained to be very optimal for that systems on the cloud so normally you pay for them by by a subscription or write in under a fuser and then boom youf this ready to use it can plug it in your service great so imagine Andrew open P ey a pen ey goes by as pay as you go which is amazing because you can have you can have users be chared by proportionately by what they use which is great and they have as well Enterprise services and Enterprise security great now congratulations you know a lot about llms but how can I Implement that carot will tell you about it don't worry I come back soon but now carot how can I deploy a service sure thanks Pablo hi everyone I'm carot gucho AI Cloud Advocate at Microsoft and I'm happy to show you today uh how you can work with large Foundation models in aure why aure in the ever evolving landscape of language Foundation models selecting the right candidate for your specific scenario is just the beginning of the journey uh once you have identify your top choices let's say it's time to put them to the test on your use case welcome to the world of asure machine learning your One-Stop platform for managing the entier machine learning life cycle after extensive research our startup has explored the current large language models landscape and we have pinpointed some strong contenders for our unique scenario uh now the real fun begins testing these models involves an interative process using experiments and precise measures to ensure they meet the mark and where do we find these models the foundation models catalog in the as machine Learning Studio is your answer asure machine learning provides a simulus experience with a userfriendly interface and here's what you can do you can easily find the foundation model of your interest by filtering your research based on task um license and name of the model you can even import new models not yet in the catalog but before you dive in it's always a good idea to get to know your model the model Cod provides a comprehensive view complete with detailed description and code samples the sample inference widget provides you with the sample input to put to the model to the test and get a taste of the results to ensure your model aligns perfectly with your workload evaluate its performance using objective metrics and your specific data set sometimes a bit of fine-tuning is necessary as machine learning empowers you to improve your model's performance with custom Training data once your model is primed and ready it's time to deploy it whether it's your original pre-train model or your finally tuned version aszure machine learning has you covered it offers realtime inference or batch end point deployment ensuring your applications can consume your model with ease when it comes to deploy large language models into production business have a word of options each with its own set of complexities cost and quality levels let's dive into these approaches and see which one suits different requirements the first approach is prompt engineering with context pre-trained large language models excel in handling General language task you can simply feed them a short prompt like a question or an incomplete sentence and they work like a charm we call this zero shot learning but here's the catch the more context you provide the better the large language model understands your request when you include detailed examples and requests your prompt it's called One Shot learning for single example and few shot learning when using multiple examples this approach is cost effective and a great starting point approach number two retrieval augmented generation large language models have their limitations they only know um what they were trained on and can't access posttraining information or private data to bridge this Gap we use retrieval augmented generation this technique adds external data in the form of chunk of documents into your promt effectively expanding the model's knowledge it's powered by Vector database tools like a vector search and it is a valuable approach when you lack the data the time or the resources to fine-tune your large language model but want to boost its performance and minimize risk of incorrect information or harmful content approach number three fine-tuned models fine-tuning is a process that customizes a large language model for a specific task it generates a new model with up ated weights and vises making this approach ideal if your business prefer coste effective and less powerful models you have strict lency requirements or you possess high quality data and ground prooof labels and you can maintain them over time last approach train your own large language model training a large language model from scratch is a huge undertaking demanding vast amounts of data skilled professionals and serious computational power you'd consider this option only if you have a very domain specific use case and an amance of domain Centric data in the world of large language model deployment does no oneid fits all solution the right approach depends on your unique requirements resources and goal also any choice we make about training and deployments we should be conscious and transparent about models limitations and use responsibly practices and tools in the next episode you'll discover more about what this mean thank you everyone and see you at the next episode
VIDEO 4: everyone my name is Nan Naran and I'm a member of the AI advocacy team at Microsoft welcome to this lesson on understanding prompt engineering fundamentals it's a part of the larger generative AI for beginners curriculum that takes you from fundamental concepts to functional application prototyping using generative AI the main goal for this lesson is to help you build your intuition for creating better prompts by iteration and validation think of prompt engineering today as being more art than science the only way you'll get better at it is through lots and lots of practice so what are we covering today today we'll talk about what prompt engineering is and why it matters we look at how to construct prompts from simple content to complex instructions we'll talk about best practices for improving the quality and relevance of your prompt responses and we'll end with a quick look at a Cod Challenge environment where you can apply these ideas in practice and explore these on your own but before we dive in let's recap what we know in terminology so far we know that generative AI refers to a type of AI that generates new content using large language models and we know that large language models are AI trained on massive data sets that are specialized to work with natural language tasks so promps are now the natural language or text inputs to an llm that allow a user or an application to program Its Behavior and influence its response so how does this relate to our Target application in audience remember that we are building an education startup with AI apps that are focused on personalized learning so let's think of what a prom based experience can look like for different users of our application an administrator may want to ask the AI to analyze all the curriculum data and identify gaps and coverage an educator may ask the AI to generate a lesson plan on the Civil War for an eighth grade audience a student may ask the AI to teach me how to solve this calculus problem by giving me hints and examples that will help me learn with that kind of context in mind you should have a sense an intuitive sense for what a prompt is and how our application users May construct these so now let's talk about prompt engineering what is prompt engineering and why should we care to do that let's kind of look under the hood and understand how prompts work remember that to a to the large language model a prompt is just a sequence of tokens the response or completion that it provides is just a prediction of the next token based on its pre- pre-trained data and most models have an Associated token limit for their inputs so one of of the reasons prompt engineering matters is that you want to design your prompts to make effective use of those tokens to get quality responses I recommend using tools like the open AI tokenizer to just you know explore your own intuition for how the prompt design influences the number of tokens and also look at how those tokens are generated once a prompt is tokenized we actually can think of Base llm Behavior as simply predicting the next token right so in this example I used the first line of a famous speech as my prompt and gave it no other instruction I used the Azure open AI chat play playground the link is there and you should try it out yourself because the assistant was programmed to see prompts as request for information it returned a response that predicted what the most popular kind of information would be if someone had given that particular query as the text input an instruction tuned llm refines this base Behavior by kind of focusing on providing more detailed instructions that can help improve the quality of the response to match the expectations of your user or application so for example here we can see that the assistant is set up with a more detailed instruction as context in the system message of the open AI chat playground and in this the assistant is told that it needs to summarize content for a second grade audience and keep the result to three to four five bullet points with this additional instruction context entering the same prompt as before now gives us a much more relevant response for our application needs so an educator who was looking to potentially use that data in a slide for that for that uh uh great audience now has just a really quick copy paste and they have their slide ready so based on this how can we Define prompt engineering I like to think of it as the process of Designing and optimizing your prompt till you get a response that meets your application or user expectations for quality and relevance just remember that this is a trial and error process where you have to iterate and validate The Prompt until you get to a point where you're satisfied it really is more art than science right now so why should we care why is prompt engineering so critical for a generative AI application Dev developer we already know that prompts are how you're going to program your large language model but there are a few factors that we can think about first these models are stochastic that means there's an inherent Randomness in the behavior which can lead to you getting different results each time you use it with the same prompt models can also hallucinate they really don't understand the input they're literally just looking at prompts as a sequence of tokens and predicting the output based on some statistics iCal knowledge so it's absolutely possible that they predict an output pattern that looks valid but is in fact not based in any factual knowledge llms also have diverse capabilities you have different models from different providers the same model has different Generations may be trained for different kinds of text uh uh outputs I mean different kinds of content outputs so knowing the features and quirks is really helpful when you want to write a prompt so you take advantage of the best things that offer and find ways to work around its limitations so let's see some examples we talked about the fact that models are stochastic so look at these two responses these two responses are responses for the exact same prompt on the exact same Azure open AI chat application with the exact same model just taken a few minutes apart and just that small variation has caused a fairly noticeable difference in the output because we didn't actually do any engineering of the promp we just put it out there think about how this would impact an application or user that was depending on that data to do something interesting so here the responses have different lengths they have different levels of detail how does that impact that user experience let's talk about hallucination so I deliberately picked a really older model GPT 3.5 uh on the chat open AI uh playround and I knew that had older data so it was easy to try hallucinations there and I asked you to generate a lesson plan for an event that doesn't exist there is no Martian war and even if there was this is 2076 so that hasn't happened yet so it must be fictional right but look at what the AI does do you see how the response actually meets our instructions but has no indicator to tell me that the result is not factually correct now think about how this could impact a teacher who's going to use this in the lesson plan but had no way of knowing or verifying that the information being given is actually rooted in real data so that brings me to the third part right model capabilities matter so Look At Me Now using the exact same prompt but on a much newer model GPD 4 that has more recent training data and also has been tuned to take advantage of the fact that it knows about hallucinations and will try to minimize their impact now see how the response still executes the task and creates that lesson plan but it now provides an additional context that says hey this is a fictional event so think now that how an educator could use this information in a more realistic way they could either throw it away and say well I only want truth or they can say hey this could be a great way to do a thought exercise with my students so all we've talked about right now is what is prompt engineering why does it matter would it be nice to see the impact of prompt Engineering in a real world application you can look no further than GitHub co-pilot a generative AI application for a developer audience that was trained on the open AI codex and was developed by GitHub in conjunction with open AI it's really a model optimized for code generation you can check the curriculum for a detailed set of links that walk you through the history of the project where they talk about the various decisions and prompt engineering uh challenges they had to face but I wanted to just show a really quick example of the application and how you as a user can engineer prompts to get the best value out of it so this is an example provided by the GitHub developer Advocates so in this first example they basically give a basic prompt hey draw me an ice cream cone with ice cream using p5.js and you can see that the image doesn't actually match your expectations right it looks more like a Target so how can we improve that in the next step The Advocates basically went in in and started refining The Prompt and if you watch how that was delivered you can see that now that does in fact look like an ice cream cone so what did they do differently well they advocated three best practices for crafting prompts set the stage with a high level goal so here it starts off by saying you need to draw me an ice cream cone with an ice cream scoop and a cherry on top then it sets simple specific tasks nothing complicated draw a triangle with a point facing down then give examples ice cream cone should be a half circle on top of the cone and if you actually go see the whole um example you'll basically see they specify the color uh the textures Etc and that's a great example of prompt Engineering in practice so we covered what prompt engineering is and why it matters now it's time to actually think about some basic concepts when you're designing your first prompt so to reiterate the simp simplest prompt is just content right you give it a sequence of words and it tries to predict the completion there are no explicit instructions here so in this particular example this is the fundamental behavior of an llm I provided the first few words of the US national anthem and you can see it immediately was able to complete it and predict the next few lines so remember this is the core behavior of an llm just prediction it doesn't understand what the meaning of that prompt is it just executes on completing it in a more complex content example the users now asking questions again there are no explicit instructions they're not telling them what to do they're just asking for information but now the application has a system prompt that sets the context for the conversation it basically defines the behavior this is an example from um open AI um examples category like there's a bunch of different templates prompt templates and examples you can try out in their playground and this is mar the sarcastic chatbot Marv's system message says hey you're a chatbot that reluctantly answers questions with sarcastic responses so it sets the context and now when the user starts adding queries you'll notice that we have a multi-t conversation where every single message between the user and the assistant responding to it can be passed in to the uh application or Prov or model and then it can kind of treat it as a sliding window where it's looking at the history of these tokens and trying to predict the next best response based on a conversation and that's a fairly complex kind of prompt Behavior now the more popular in use case these days is when there are explicit instructions given by the user themselves so here in a very very simple case a simple instruction the user just has a text prompt that says do this here they're saying write me a description of the Civil War really simple right and it delivers in a more complex version of this instruction prompt the user provides more detail just like we saw at the GitHub co-pilot case they provide simple instructions and more details on what they're looking for now look at the difference between this and the previous example see how the response is now structured to be more aligned to that user's need and how the content is more focused on the specific details asked you're already seeing the response quality improve based on engineering that prompt but wait we can also instruct the AI to provide the response in a desired format that's yet another interesting instruction we can give so here we saying hey could you return the output to me as a Json file note how this is effectively engineering the starting prompt we started with a very simple prompt looked at the response said hm we could do better and kept iterating on it till it gets to a point where in this case let's say an educator gets the result that they want in a format that they need and you can see that it actually does return something that is Json formatted uh I've only put a snippet of the response and if you run it yourself you should see the whole thing and of course now that we know how a simple content prompt works and you know how instruction let prompts work you can start combining instructions with content and this is actually a really interesting whole category of how you can engineer better prompts because when you provide primary content you're effectively saying I have an instruction this is a task I want you to do and this Prim primary content is what I want you to see as the main source or like a more relevant source for the thing I want you to do so it can refine Its Behavior to be more relevant to your specific context here the prompt input has a paragraph As the primary content and the instruction is asking you to summarize it in two sentences note now that the educator gets a summary the way they want it it's two lines and it gives them a response that they can trust more because they actually provided the source for the summarization but we can take this
        """,
        "image": "https://telegra.ph/file/281a6c6fd930cc00fdc4a.jpg",
        "videos": [
            "https://www.youtube.com/watch?v=vf_mZrn8ibc&list=PLmsFUfdnGr3zAgBMu4l1W713a0W__zAMl&index=1",
            "https://youtu.be/J1mWzw0P74c?list=PLmsFUfdnGr3zAgBMu4l1W713a0W__zAMl",
            "https://youtu.be/R3sHRPP2G7A?list=PLmsFUfdnGr3zAgBMu4l1W713a0W__zAMl",
            "https://youtu.be/32GBH6BTWZQ?list=PLmsFUfdnGr3zAgBMu4l1W713a0W__zAMl"
        ],

    },
    {
        "name": "Learn Adobe Illustrator",
        "description": "Learn Adobe Illustrator with a focus on creating logos, icons, and vector graphics.",
        "instructor": "Gareth David Studio",
        "content": """
INTORDUCTION VIDEO: Hello and welcome to the complete beginners guide to Adobe Illustrator, brought to you by tastytuts.com. This is a course created for beginners to Adobe Illustrator. The topics that are going to be covered in this course are the basics. So whether you have the most up to date version of Illustrator or you are using an older version, you should be able to follow along just fine. For this course, I will be using Adobe Illustrator CC. In this series, we will be starting from the very beginning and working our way across 19 episodes to learn all the basics and create an illustration project. To help break down the process, I have structured the course in three main sections -- introduction, essential practice and test project. In the introduction section, I will be introducing you to Illustrator and bringing you up to speed with some of the things you need to be aware of before we continue onto the essential practice section. In the essential practice section, we are going to look closely at some of the creative tools and principles in Illustrator. Here you will have the opportunity to get hands on with the various worksheets I have designed and prepared for you to practice with. When we get to the test project section, we will be using all that we have learned in the essential practice section to create a project from scratch. After watching this series, you will be able to create your very own vector artwork ready to print. Now, if you wish to follow along with this course, you can download the entire project folder for free. The link is in the description. This folder contains all the worksheets, fonts and project files necessary to follow along. If you wish to skip ahead or back at any point in the course, you can find every episode link in the descriptions of each video. Also, I suggest you download the PDF worksheet. You can save this to your computer and come back at any point. This is an interactive PDF, which has been designed to enhance this course experience. This contains all the relevant video and project download links. So I recommend you download this PDF. And you can also find the download link for this in the description. So what is Adobe Illustrator? Well Adobe Illustrator is part of the Adobe Creative Suite. And in recent years has become industry standard for creating vector artwork and the simple layout for print. If you need to create logos, illustrations, posters, infographics, T-shirt designs and flyers, Illustrator is a program to create them in. The tools in Illustrator make it very easy to create and modify shapes and strokes to build your compositions and bring your design to life. You can also import pixel based images to add to your layouts as part of your designs. So what are we going to create on this course? Now for all you artists, illustrators and designers out there who love to draw and sketch on paper, hopefully this course is really going to help you. We are going to bring a hand drawn sketch, which has been scanned and placed into Illustrator and converted into vector artwork. Then, we are going to use this vector artwork in a poster and T-shirt design. So why a T-shirt and poster design? Well we are going to explore a scenario where we are going to design for print. So we are going to be working with CMYK colors for the poster. Though, for the T-shirt design, we will need to stay within a budget and use only Pantone colors that the printer requires. So we are going to explore how to incorporate pantones and CMYK swatches into our artwork. So let's take a look at the finished document. So here we are in Adobe Illustrator. And here you are looking at the finished artwork document we are going to build up to. So this document consists of four art boards. The first two art boards contain the development stages in our project. And the last two art boards contain the finished designs. On art board one, we have a vector drawing composition, which was traced from a sketch drawing, which was scanned and placed into our document. This complex composition contains multiple shapes and stroke vectors. On art board two, we have the same artwork, but this is a single flat vector. The artwork from the first art board has been compounded into a single vector here. On art board three is the finished poster artwork. Here we have lots of colors, gradient effects, and type objects. On the last art board is the T-shirt design. And here we can also see our pantone references, which we are going to use to incorporate correct pantone colors into our artwork. Once we have finished the poster and T-shirt design, we are then going to export the artwork to the correct format for a printer to print the design to specification. Here are two PDF's we are going to finish with. If we look carefully at the first PDF on the left, we can see that this is just one page. And we can see a number of marks and guides around the outside. Now these are bleed and crop marks that the printer is going to use to correctly trim the artwork. Also, we have some color squares to help the printer collaborate the colors accurately with their printers. All these marks and guides have been generated upon exporting the artwork from the Illustrator document. And we will be taking a look at how to do this at the end of the course. Over to the right, we have the T-shirt artwork PDF. Now this is a little different from the poster example. This artwork is going to be printed onto a T-shirt. So we can see here that the artwork is set on a white background. And some of the color in the skull artwork is also white. This is where the color of the T-shirt is going to come through and fill these areas. Notice on this example, we do not have any marks and bleeds. Well, this design is not going to be printed on paper. This will become a transfer that will be heat pressed onto a T-shirt so we do not need marks and bleeds here. So that is everything we are going build up to on this course. So once you have downloaded the project folder, let's get into it. And we are going to begin with the first video in the course. Interface introduction to Adobe Illustrator. So I will see you in the next video.
\n\nFIRST LESSON: In this video we are going to take a look at the Adobe Illustrator interface. I'm going to show you around and introduce you to some of the things you need to be aware of. Now I am currently using Illustrator CC for a Mac. If you're using an earlier version, or Windows, some things may be a little different in parts, but in principle it should be the same. If you have Illustrator open and wish to follow along you will need to first come up to \"window,\" scroll down to \"workspace,\" then scroll down and select \"essentials.\" Then to make sure you end up with the same set up you see here we must again go to \"window,\" \"workspace,\" and then scroll down and select \"reset essentials.\" This will then set the interface to the essentials default layout and you should have something that looks like this. What you will come to learn later on is that you can customize this layout, but what would help right now is for you to have the same layout so you can follow along with me. Now, if for some reason you don't see the same as mine, don't panic. It's not a problem. Just follow along and you should be fine. Now, on a Mac, by default, the application frame is switched off. Some of you may prefer to have this on and some of you may like this off. So let me show you what this is. If I come to \"window\" and scroll down to \"application frame\" we can see that there is no tic next to this, as it's currently set off. If I click this we can now see a solid gray background. This is the application frame. If I turn it off again -- \"windows,\" \"application frame\" -- we can see the desktop. My personal preference is to have the application frame on so I'm not distracted by the desktop background. So this is Adobe CC and with CS6 and CC we have this dark interface. If you're using an earlier version you will be looking at the light interface. Now, if for whatever reason you wish to toggle the interface color, if you come to \"illustrator,\" on the top bar, and scroll down to \"preferences\" and select \"user interface,\" you can toggle the lightness and darkness here. I'm going to go with \"medium-dark.\" So to begin, I'm going to open up a document. To follow along you can also open up this document. This can be found in the \"introduction\" folder in the \"project\" folder. Now, you can download this folder for free. The download link is in the description. So I have my project folder here in the desktop. When you have the project folder, simply open it, then click on \"introduction,\" \"interface introduction,\" \"versions,\" and select the version of Illustrator you're using -- in my case it's CC -- and open the \"interface introduction\" file. This file is going to help to demonstrate various functionality of the program, which we are going to be covering a little later on in this video. So as you can see, this is a document and it contains four art boards with an object on each page. Also, we have some artwork elements in the pasteboard area. Okay, so let's take a closer look at the interface. On the far left we have this tall, slim panel. This is the tools panel and contains all the tools that can be used in Illustrator. And as you can see, we have lots of icons. To activate a tool we simply click it or press one of the many shortcut buttons on the keyboard. We know which tool is active because it has a highlight square behind it on the tools panel and also you will notice that the mouse cursor will change, indicating which tool we have active. In Illustrator we will be using many tools and most tools have their own unique mouse cursor. Now, if we look carefully we can also see that some of the icons have little white arrows in the bottom, right corner. If we click and hold on the icon this will reveal more tools in that set. For example, if I click and hold on the pen tool we can see an extra three tools within that set. If I click on the shape tool we can see a variety of shapes that can be created very easily. And if we move our mouse cursor over the tab on the right we can expand the tools panel out, which can be very useful. And to remove this we can simply click the X in the top left corner. So keep in mind that some tools work in sets. Now, if we take a closer look at the bottom of this panel we can see two overlapping squares. One appears to be a block and one appears to be an outline of a square. Now, if you're new to Illustrator you may not be familiar with this. What this represents is the fill color and the stroke color of an object on the canvas area. The top square is the fill and the background square is the stroke. So right now we can see that the fill color on the top is white and the stroke color is black. Now, if I come over to the canvas area and select an object -- to do this I will first need to choose the selection tool. This tool is located at the top of the tools menu and is recognized as the black arrow. With this active let's select this yellow circle here. Then you can see that the fill color and stroke in the bottom of the tools menu has changed in accordance to the selected object. You can see the fill color is yellow and the stroke is orange. This is important because it helps tell us that this object is just one object and not two separate objects. For example, with the object selected I can click and move this around like so. I'm just going to undo that and put it back in place. And if I come over and select another object we can see the fill color and stroke color will change again. Now, if you look closely, just above the fill and stroke color on the tools panel, we have this little button here called \"swap fill and stroke.\" And if I press this it's going to swap the stroke and color fill like so. So very easily we can swap the fill color and stroke color. Now, to the left of the \"swap fill and stroke\" we have another little button and this is the \"default fill and stroke.\" If I press this it's going to set my fill and stroke squares to black and white, though keep in mind, if you have an object selected on your canvas area, like I have this circle selected here, and press it you will see the object has changed to black and white with a default stroke applied. So I'm going to undo this, click off the object to deselect, and click on the \"default fill and stroke button\" and now we are back to the default black and white stroke and fill. So as you can see the tools menu is currently in two columns. If we look closely up to the top left of the tools panel we can see these little arrows pointing left. If I come and click this once we can change the panel to a single column and if we press this again we can go back to the double column. For the duration of this course I'm going to click this and set my tools panel to a single row. Now, if we move to the top of our window we can see the standard tool bar across the top. From here we can access various properties and controls, but we are not going to touch on that too much right now. Just under the top tool bar we have the control panel. Now, this control panel is really useful as this will display various properties of a particular tool or object you have selected at any given time. So right now we can see some properties here. If I close the document we can see that it all disappears and that is because now we have nothing going on. If I open up the document again -- and I can do this easily by coming to \"file,\" open \"recent,\" and selecting the file we can see the control panel kick into action. You will soon realize that this is one of the most key panels in this program and as you use Illustrator you will be referring to this control panel a lot. So let's take a look at how it works. So right now I don't have anything selected. I'm going to choose the selection tool from the top of the tools menu and select an object on the canvas area. Let's select this blue circle here. Now, you will see the control panel change in accordance to the object. Just like earlier we can see at the bottom of the tools panel the fill and color stroke has changed, but also we can see this on the control panel. If we click \"down\" we can access the \"swatches\" panel and change the color of the fill and the stroke very easily. Also, here we have the stroke property. Here we can easily toggle the stroke size and also I can adjust the variable width from a choice of options. If I come across I can also change the brush definition and even toggle the opacity of this object. So I'm going to undo all this and deselect the object by clicking off it. This time I'm going to select the \"text\" tool from the menu. This time in the control panel we can see some new properties. We have properties for font choice, font style, font size, and some formatting options. All of which I can use when I add text to the canvas area. So keep in mind, as you use your tools, to keep an eye on the control panel, as this is really useful. Moving over to the right hand side we have another slim panel. Now, like the tools panel over on the left this contains an array of subpanels that are represented by these icons. What you will soon discover is that these panels, like the control panel, are essential in order to produce work in Adobe Illustrator. In order to have a swift workflow in this program it will help to have a comfortable setup of these panels. Now, in Illustrator you can arrange these panels in various ways. I'll be demonstrating how to do this in the next episode and recommending an effective set up. Though what you see here is a default setup. Now, as we click down the panels on each icon we will begin to reveal the panels. For example, we have \"color,\" \"swatches,\" \"brushes,\" and \"stroke.\" Now, these panels contain various tools and properties regarding objects on the canvas. Also, if you look carefully, these panels also include subpanels as tabs. For example, on this stroke panel, we also have the \"gradient\" panel and the \"transparency\" panel. If we come down and click on the \"layers\" panel we can see that all our objects in the document are existing on one layer and I can toggle the visibility of this and if I click on the \"artboard\" tab we can see that this document contains four artboards. And if I click once again on the icon in the panel this will disappear, giving us full visibility of the canvas area. Now, if I come to the very bottom of the window we have this thin strip. This also contains some useful tools. If we look over on the far left we have the magnification of our document. We can use this to zoom in and out of our document like so. To the right of this we have the \"artboard navigation.\" We can use this to quickly maneuver through the document to a particular artboard or this will give you a clear indication of which artboard you are on at any given time. So next I want to touch on document tabs. Now, what are document tabs? Okay, so currently we have this document open and if we look carefully in the top left corner, just under the control panel, we have a tab that shows a document name. Now, sometimes you may find yourself using multiple documents at any given time. For example, let's quickly create a new document. I'm going to come to \"file,\" \"new,\" and just click \"ok\" and there it is. And let's make one more. And we have another. Now, look again closely at the top left, just under the control panel and this time we have three tabs. Now, we can click these to navigate to other documents. If I click the far left tab we are back to our first document and if I quickly select an object and press command C to copy I can click on the third tab to go back to the new document and simply paste in the object into the canvas like so. So when we start to use multiple documents later on in the course we will be using document tabs in this way. So I'm going to close these two docs down by clicking the X on the far left of the tabs until I am back to my original document. The last thing I want to talk about here is the canvas area. When you create a document you will have a white area which represents your artboard size and a gray area around the canvas. As you can see we have four artboards sitting on the gray area. The gray area here is called the pasteboard. We can put any artwork we want on this, which we don't want to include in our main composition. This is pretty handy if we want to keep bits of artwork on the side to use later. In my example we can see I have some vector artwork sitting in the pasteboard area here. So that's a brief overview of the Adobe Illustrator interface. In the next video I will be taking a closer look at the work panels where I will be showing you how you can customize your panel layout to get a more comfortable workspace. So I'll see you in the next video.

                    """,
        "image": "https://telegra.ph/file/f734fffd68f2e286005f7.jpg",
        "videos": [
            "https://youtu.be/IBouhf4seWQ?list=PLYfCBK8IplO4X-jM1Rp43wAIdpP2XNGwP",
            "https://youtu.be/QKWnkIPur2Q?list=PLYfCBK8IplO4X-jM1Rp43wAIdpP2XNGwP",
            "https://youtu.be/2E9oGKd0Ayg?list=PLYfCBK8IplO4X-jM1Rp43wAIdpP2XNGwP"
        ],
    },
]
